{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training\n",
    "This file is used for training the classification model. In this case, the model is CNN (InceptionResNetV2).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Requirments**\n",
    "- Perform preprocessing in Step1_Preprocessing.ipynb.\n",
    "- Manually create the folders (i.e., InceptionResNetV2/model, InceptionResNetV2/modelWeight, and InceptionResNetV2/pic).\n",
    "- Define the data paths in the Setup section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Version of libraries\n",
    "- Tensorflow: 2.4.0\n",
    "- Keras: 2.4.0\n",
    "- pandas: 1.2.1\n",
    "- matplotlib 3.3.3\n",
    "- numpy 1.19.5\n",
    "- scikit-learn 0.24.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrU6k7Ln-J2-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the library for data importing and training process.\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, BatchNormalization ,GlobalAveragePooling2D, Input, concatenate, AveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras import backend as K\n",
    "from keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHmKKvvyGJMI"
   },
   "outputs": [],
   "source": [
    "# Path for Training dataset and Validation dataset.\n",
    "trainDir = \"/xxx/data/Train\"\n",
    "valDir = \"/xxx/data/Valid\"\n",
    "\n",
    "#Path for saving model, modelWeight , accuracy and loss after training.\n",
    "saveModel = \"/xxx/InceptionResNetV2/model\"\n",
    "saveModelW = \"/xxx/InceptionResNetV2/modelWeight\"\n",
    "savePic = \"/xxx/InceptionResNetV2/pic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdUieVtH-J3a"
   },
   "outputs": [],
   "source": [
    "# Callback and Save Model Weights when Fit model.\n",
    "class decaylr_loss(keras.callbacks.Callback):\n",
    " #For ERROR that occur when fitting the model in GCP \"\"\" AttributeError: .... no attribute '_implements_train_batch_hooks' \"\"\"  \n",
    "    def _implements_train_batch_hooks(self): return True\n",
    "    def _implements_test_batch_hooks(self): return True\n",
    "    def _implements_predict_batch_hooks(self): return True\n",
    "  #####################################################################  \n",
    "    def __init__(self):\n",
    "        super(decaylr_loss, self).__init__()\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        loss=logs.get('loss')\n",
    "        print(\"loss: \",loss)\n",
    "        old_lr = 0.001 #needs some adjustments\n",
    "        new_lr= old_lr*np.exp(loss) #lr*exp(loss)\n",
    "        print(\"New learning rate: \", new_lr)\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "lrate = decaylr_loss()\n",
    "\n",
    "# Checkpoint for model, if the valid accuracy is improve the model will be save at some interval,so the model or weights can be loaded later to continue the training from the state saved.\n",
    "wdir = saveModelW\n",
    "filepath = os.path.join(wdir ,'inception_resnetv2_weight.best.h5')\n",
    "checkpoint = ModelCheckpoint(filepath , monitor='val_accuracy', verbose=1 , save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J5p69Wy-J3i"
   },
   "outputs": [],
   "source": [
    "# Initail Image size and batch size use for Training.\n",
    "img_size = 256\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5vKWvBg-J3t"
   },
   "outputs": [],
   "source": [
    "# Import data from Training dataset directory with ImageDataGenerator from Keras.\n",
    "imgDataGen = ImageDataGenerator()\n",
    "\n",
    "train_data = imgDataGen.flow_from_directory( trainDir, target_size = (img_size, img_size), color_mode='rgb', batch_size = batch_size, class_mode='categorical')\n",
    "valid_data = imgDataGen.flow_from_directory( valDir, target_size = (img_size, img_size), color_mode='rgb', batch_size = batch_size, class_mode ='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiYhvF6V-J33"
   },
   "outputs": [],
   "source": [
    "# To check the classes are correct or not.\n",
    "print (\"Train : \" , list(train_data.class_indices.keys())) \n",
    "print (\"Valid : \" , list(valid_data.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul_0Xgj3-J4A"
   },
   "outputs": [],
   "source": [
    "#To count the number of imported image.\n",
    "print(train_data.batch_size , 'batches train = ' , train_data.n , 'imgs')\n",
    "print(valid_data.batch_size,'batches valid = ', valid_data.n, 'imgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhFGgQKMjXRq"
   },
   "source": [
    "\n",
    "## Define CNN Model : Inception_resnet_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36S8JpKZGJML",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# base model is pre-trained weights on ImageNet\n",
    "base_model = InceptionResNetV2(\n",
    "    weights='imagenet', \n",
    "    include_top=False,\n",
    "    input_shape=(256,256,3)\n",
    ")\n",
    "\n",
    "x = base_model.output \n",
    "\n",
    "# added layers to the base model\n",
    "x = AveragePooling2D(pool_size=(6, 6))(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# add softmax activation\n",
    "predictions = Dense(n_classes, activation='softmax')(x)    \n",
    "\n",
    "loaded_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "print('Use a base model with pre-trained weights on ImageNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5DYAfKHGJMM"
   },
   "outputs": [],
   "source": [
    "#To check the model that is loaded.\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqLlCH9FUWYb"
   },
   "source": [
    "## Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-CVytByGJMM"
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent (SGD) is an optimizer which will performs a parameter update for each training example and label.\n",
    "# Learning rate (lr) is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
    "# Momentum is a method which helps accelerate gradients vectors in the right directions, thus leading to faster converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLxkwTPX-J4n"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set the optimizer for model before training.\n",
    "# Use 0.01 learning rate (lr) at the start and use learning rate decay method which will reduce the learning rate overtime when training and validation.\n",
    "# Use 0.9 momentum, when training, it would denoise the data when training and validation.\n",
    "opt = SGD(lr=.01, momentum=.9)\n",
    "\n",
    "# Compile the model before training\n",
    "# Use categorical_crossentropy for more than 2 label datasets\n",
    "# Use accuracy for metrics to judge the performance when training and validation\n",
    "loaded_model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JrNV168-J4t"
   },
   "outputs": [],
   "source": [
    "# Use for step_per_epoch when training and validation.They define how many batches of samples to use in one epoch for training dataset and validation dataset.\n",
    "step_size_train = train_data.n//train_data.batch_size   # steps_per_epoch\n",
    "step_size_val = valid_data.n//valid_data.batch_size     # validation_steps\n",
    "print('each epoch is ',step_size_train,step_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPC0qvRG-J40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# One epoch means all training dataset and validation dataset processed one times.\n",
    "# History is infomation when training and validation such as training accuracy, valid accuracy which will be used after this section.\n",
    "# Fit the model is the process to train and validate the model.\n",
    "epochs = 100\n",
    "hist = History()\n",
    "loaded_model.fit(train_data,\n",
    "                          validation_data = valid_data,                         \n",
    "                          steps_per_epoch = step_size_train,       \n",
    "                          validation_steps = step_size_val,\n",
    "                          epochs = epochs,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = [lrate , checkpoint, hist]) #earlystopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kWZ5sB6-J46"
   },
   "outputs": [],
   "source": [
    "# plot acc and loss per epochs after training.\n",
    "print(hist.history.keys())\n",
    "\n",
    "# Plot training accuracy line.\n",
    "plt.plot(hist.history['accuracy'])\n",
    "# Plot validtion accuracy line.\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "# Title of the graph.\n",
    "plt.title('model accuracy')\n",
    "# Define y-axis of graph as accuracy.\n",
    "plt.ylabel('accuracy')\n",
    "# Define x-axis of graph as number of epoch.\n",
    "plt.xlabel('epoch')\n",
    "# To address train and valid legend.\n",
    "plt.legend(['train', 'valid'])\n",
    "# To save the graph at the specified path.\n",
    "plt.savefig(os.path.join(savePic,'iInceptionResNetV2_accuracy.jpeg'), dpi=1000, bbox_inches='tight') \n",
    "# show the graph as output.\n",
    "plt.show()\n",
    "\n",
    "# Plot training loss line.\n",
    "plt.plot(hist.history['loss'])\n",
    "# Plot validation loss line.\n",
    "plt.plot(hist.history['val_loss'])\n",
    "# Title of the graph.\n",
    "plt.title('model loss')\n",
    "# Define y-axis as loss.\n",
    "plt.ylabel('loss')\n",
    "# Define x-axis as epoch.\n",
    "plt.xlabel('epoch')\n",
    "# To address train and valid legend.\n",
    "plt.legend(['train', 'valid'])\n",
    "# To save the graph at the specified path.\n",
    "plt.savefig(os.path.join(savePic,'InceptionResNetV2_loss.jpeg'), dpi=1000, bbox_inches='tight') \n",
    "# show the graph as output.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmLW5LFj-J5B"
   },
   "outputs": [],
   "source": [
    "# Save model after training process to the specified path\n",
    "loaded_model.save(os.path.join(saveModel,'InceptionResNetV2.h5'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionResNetV2-Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
